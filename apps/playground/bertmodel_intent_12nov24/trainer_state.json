{
  "best_metric": 3.886491298675537,
  "best_model_checkpoint": "intent_model_5epochs/checkpoint-840",
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 840,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05952380952380952,
      "grad_norm": 1.453575849533081,
      "learning_rate": 1.9761904761904763e-05,
      "loss": 5.6117,
      "step": 10
    },
    {
      "epoch": 0.11904761904761904,
      "grad_norm": 1.5305248498916626,
      "learning_rate": 1.9523809523809524e-05,
      "loss": 5.44,
      "step": 20
    },
    {
      "epoch": 0.17857142857142858,
      "grad_norm": 1.7314845323562622,
      "learning_rate": 1.928571428571429e-05,
      "loss": 5.2712,
      "step": 30
    },
    {
      "epoch": 0.23809523809523808,
      "grad_norm": 1.628421664237976,
      "learning_rate": 1.904761904761905e-05,
      "loss": 5.06,
      "step": 40
    },
    {
      "epoch": 0.2976190476190476,
      "grad_norm": 1.4606175422668457,
      "learning_rate": 1.880952380952381e-05,
      "loss": 4.9016,
      "step": 50
    },
    {
      "epoch": 0.35714285714285715,
      "grad_norm": 1.4350794553756714,
      "learning_rate": 1.8571428571428575e-05,
      "loss": 4.7483,
      "step": 60
    },
    {
      "epoch": 0.4166666666666667,
      "grad_norm": 1.309428095817566,
      "learning_rate": 1.8333333333333333e-05,
      "loss": 4.6369,
      "step": 70
    },
    {
      "epoch": 0.47619047619047616,
      "grad_norm": 1.2035799026489258,
      "learning_rate": 1.8095238095238097e-05,
      "loss": 4.5366,
      "step": 80
    },
    {
      "epoch": 0.5357142857142857,
      "grad_norm": 1.1927211284637451,
      "learning_rate": 1.785714285714286e-05,
      "loss": 4.4619,
      "step": 90
    },
    {
      "epoch": 0.5952380952380952,
      "grad_norm": 1.0510681867599487,
      "learning_rate": 1.761904761904762e-05,
      "loss": 4.3825,
      "step": 100
    },
    {
      "epoch": 0.6547619047619048,
      "grad_norm": 0.9818142056465149,
      "learning_rate": 1.7380952380952384e-05,
      "loss": 4.3155,
      "step": 110
    },
    {
      "epoch": 0.7142857142857143,
      "grad_norm": 0.9784232378005981,
      "learning_rate": 1.7142857142857142e-05,
      "loss": 4.2808,
      "step": 120
    },
    {
      "epoch": 0.7738095238095238,
      "grad_norm": 0.857754111289978,
      "learning_rate": 1.6904761904761906e-05,
      "loss": 4.2356,
      "step": 130
    },
    {
      "epoch": 0.8333333333333334,
      "grad_norm": 0.9683847427368164,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 4.207,
      "step": 140
    },
    {
      "epoch": 0.8928571428571429,
      "grad_norm": 0.8282454013824463,
      "learning_rate": 1.642857142857143e-05,
      "loss": 4.1796,
      "step": 150
    },
    {
      "epoch": 0.9523809523809523,
      "grad_norm": 0.8370494246482849,
      "learning_rate": 1.6190476190476193e-05,
      "loss": 4.1467,
      "step": 160
    },
    {
      "epoch": 1.0,
      "eval_loss": 4.038261413574219,
      "eval_runtime": 7.9727,
      "eval_samples_per_second": 674.172,
      "eval_steps_per_second": 5.268,
      "step": 168
    },
    {
      "epoch": 1.0119047619047619,
      "grad_norm": 0.6392537355422974,
      "learning_rate": 1.5952380952380954e-05,
      "loss": 4.1315,
      "step": 170
    },
    {
      "epoch": 1.0714285714285714,
      "grad_norm": 0.7004905939102173,
      "learning_rate": 1.5714285714285715e-05,
      "loss": 4.1133,
      "step": 180
    },
    {
      "epoch": 1.130952380952381,
      "grad_norm": 0.6495776772499084,
      "learning_rate": 1.5476190476190476e-05,
      "loss": 4.0976,
      "step": 190
    },
    {
      "epoch": 1.1904761904761905,
      "grad_norm": 0.6355823278427124,
      "learning_rate": 1.523809523809524e-05,
      "loss": 4.0761,
      "step": 200
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.6236639618873596,
      "learning_rate": 1.5000000000000002e-05,
      "loss": 4.0731,
      "step": 210
    },
    {
      "epoch": 1.3095238095238095,
      "grad_norm": 0.548550546169281,
      "learning_rate": 1.4761904761904763e-05,
      "loss": 4.0558,
      "step": 220
    },
    {
      "epoch": 1.369047619047619,
      "grad_norm": 0.5461500287055969,
      "learning_rate": 1.4523809523809524e-05,
      "loss": 4.0503,
      "step": 230
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 0.5444357395172119,
      "learning_rate": 1.4285714285714287e-05,
      "loss": 4.038,
      "step": 240
    },
    {
      "epoch": 1.4880952380952381,
      "grad_norm": 0.4975106418132782,
      "learning_rate": 1.4047619047619048e-05,
      "loss": 4.0251,
      "step": 250
    },
    {
      "epoch": 1.5476190476190477,
      "grad_norm": 0.48334363102912903,
      "learning_rate": 1.3809523809523811e-05,
      "loss": 4.0174,
      "step": 260
    },
    {
      "epoch": 1.6071428571428572,
      "grad_norm": 0.47159913182258606,
      "learning_rate": 1.3571428571428574e-05,
      "loss": 4.0167,
      "step": 270
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 0.5363001227378845,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 4.0139,
      "step": 280
    },
    {
      "epoch": 1.7261904761904763,
      "grad_norm": 0.6513432860374451,
      "learning_rate": 1.3095238095238096e-05,
      "loss": 4.0092,
      "step": 290
    },
    {
      "epoch": 1.7857142857142856,
      "grad_norm": 0.4149801433086395,
      "learning_rate": 1.2857142857142859e-05,
      "loss": 4.0024,
      "step": 300
    },
    {
      "epoch": 1.8452380952380953,
      "grad_norm": 0.48631754517555237,
      "learning_rate": 1.261904761904762e-05,
      "loss": 4.0013,
      "step": 310
    },
    {
      "epoch": 1.9047619047619047,
      "grad_norm": 0.44813957810401917,
      "learning_rate": 1.2380952380952383e-05,
      "loss": 3.9917,
      "step": 320
    },
    {
      "epoch": 1.9642857142857144,
      "grad_norm": 0.43832436203956604,
      "learning_rate": 1.2142857142857142e-05,
      "loss": 3.9902,
      "step": 330
    },
    {
      "epoch": 2.0,
      "eval_loss": 3.922874927520752,
      "eval_runtime": 7.9808,
      "eval_samples_per_second": 673.49,
      "eval_steps_per_second": 5.263,
      "step": 336
    },
    {
      "epoch": 2.0238095238095237,
      "grad_norm": 0.4868151545524597,
      "learning_rate": 1.1904761904761905e-05,
      "loss": 3.9839,
      "step": 340
    },
    {
      "epoch": 2.0833333333333335,
      "grad_norm": 0.39299342036247253,
      "learning_rate": 1.1666666666666668e-05,
      "loss": 3.98,
      "step": 350
    },
    {
      "epoch": 2.142857142857143,
      "grad_norm": 0.3797580301761627,
      "learning_rate": 1.1428571428571429e-05,
      "loss": 3.9733,
      "step": 360
    },
    {
      "epoch": 2.2023809523809526,
      "grad_norm": 0.49115246534347534,
      "learning_rate": 1.1190476190476192e-05,
      "loss": 3.9786,
      "step": 370
    },
    {
      "epoch": 2.261904761904762,
      "grad_norm": 0.4408043920993805,
      "learning_rate": 1.0952380952380955e-05,
      "loss": 3.9703,
      "step": 380
    },
    {
      "epoch": 2.3214285714285716,
      "grad_norm": 0.48833954334259033,
      "learning_rate": 1.0714285714285714e-05,
      "loss": 3.971,
      "step": 390
    },
    {
      "epoch": 2.380952380952381,
      "grad_norm": 0.40280771255493164,
      "learning_rate": 1.0476190476190477e-05,
      "loss": 3.9694,
      "step": 400
    },
    {
      "epoch": 2.4404761904761907,
      "grad_norm": 0.5902968645095825,
      "learning_rate": 1.0238095238095238e-05,
      "loss": 3.965,
      "step": 410
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.37766778469085693,
      "learning_rate": 1e-05,
      "loss": 3.9619,
      "step": 420
    },
    {
      "epoch": 2.5595238095238093,
      "grad_norm": 0.3525618314743042,
      "learning_rate": 9.761904761904762e-06,
      "loss": 3.9645,
      "step": 430
    },
    {
      "epoch": 2.619047619047619,
      "grad_norm": 0.33324697613716125,
      "learning_rate": 9.523809523809525e-06,
      "loss": 3.957,
      "step": 440
    },
    {
      "epoch": 2.678571428571429,
      "grad_norm": 0.31756865978240967,
      "learning_rate": 9.285714285714288e-06,
      "loss": 3.9544,
      "step": 450
    },
    {
      "epoch": 2.738095238095238,
      "grad_norm": 0.36953309178352356,
      "learning_rate": 9.047619047619049e-06,
      "loss": 3.9499,
      "step": 460
    },
    {
      "epoch": 2.7976190476190474,
      "grad_norm": 0.49746814370155334,
      "learning_rate": 8.80952380952381e-06,
      "loss": 3.9533,
      "step": 470
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 0.4416143298149109,
      "learning_rate": 8.571428571428571e-06,
      "loss": 3.9503,
      "step": 480
    },
    {
      "epoch": 2.9166666666666665,
      "grad_norm": 0.30260327458381653,
      "learning_rate": 8.333333333333334e-06,
      "loss": 3.9472,
      "step": 490
    },
    {
      "epoch": 2.9761904761904763,
      "grad_norm": 0.34206193685531616,
      "learning_rate": 8.095238095238097e-06,
      "loss": 3.9509,
      "step": 500
    },
    {
      "epoch": 3.0,
      "eval_loss": 3.8973844051361084,
      "eval_runtime": 7.959,
      "eval_samples_per_second": 675.335,
      "eval_steps_per_second": 5.277,
      "step": 504
    },
    {
      "epoch": 3.0357142857142856,
      "grad_norm": 0.2965967059135437,
      "learning_rate": 7.857142857142858e-06,
      "loss": 3.9502,
      "step": 510
    },
    {
      "epoch": 3.0952380952380953,
      "grad_norm": 0.33575689792633057,
      "learning_rate": 7.61904761904762e-06,
      "loss": 3.9456,
      "step": 520
    },
    {
      "epoch": 3.1547619047619047,
      "grad_norm": 0.32626819610595703,
      "learning_rate": 7.380952380952382e-06,
      "loss": 3.9434,
      "step": 530
    },
    {
      "epoch": 3.2142857142857144,
      "grad_norm": 0.36480578780174255,
      "learning_rate": 7.1428571428571436e-06,
      "loss": 3.9441,
      "step": 540
    },
    {
      "epoch": 3.2738095238095237,
      "grad_norm": 0.2729274332523346,
      "learning_rate": 6.9047619047619055e-06,
      "loss": 3.9429,
      "step": 550
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 0.2667715549468994,
      "learning_rate": 6.666666666666667e-06,
      "loss": 3.9405,
      "step": 560
    },
    {
      "epoch": 3.392857142857143,
      "grad_norm": 0.2726883888244629,
      "learning_rate": 6.4285714285714295e-06,
      "loss": 3.9374,
      "step": 570
    },
    {
      "epoch": 3.4523809523809526,
      "grad_norm": 0.2849644124507904,
      "learning_rate": 6.1904761904761914e-06,
      "loss": 3.9379,
      "step": 580
    },
    {
      "epoch": 3.511904761904762,
      "grad_norm": 0.3218638300895691,
      "learning_rate": 5.9523809523809525e-06,
      "loss": 3.939,
      "step": 590
    },
    {
      "epoch": 3.571428571428571,
      "grad_norm": 0.31093844771385193,
      "learning_rate": 5.7142857142857145e-06,
      "loss": 3.9344,
      "step": 600
    },
    {
      "epoch": 3.630952380952381,
      "grad_norm": 0.45878857374191284,
      "learning_rate": 5.476190476190477e-06,
      "loss": 3.9369,
      "step": 610
    },
    {
      "epoch": 3.6904761904761907,
      "grad_norm": 0.30674371123313904,
      "learning_rate": 5.2380952380952384e-06,
      "loss": 3.9354,
      "step": 620
    },
    {
      "epoch": 3.75,
      "grad_norm": 0.2598991394042969,
      "learning_rate": 5e-06,
      "loss": 3.938,
      "step": 630
    },
    {
      "epoch": 3.8095238095238093,
      "grad_norm": 0.2548385560512543,
      "learning_rate": 4.761904761904762e-06,
      "loss": 3.9358,
      "step": 640
    },
    {
      "epoch": 3.869047619047619,
      "grad_norm": 0.33580559492111206,
      "learning_rate": 4.523809523809524e-06,
      "loss": 3.9359,
      "step": 650
    },
    {
      "epoch": 3.928571428571429,
      "grad_norm": 0.2467881292104721,
      "learning_rate": 4.2857142857142855e-06,
      "loss": 3.9377,
      "step": 660
    },
    {
      "epoch": 3.988095238095238,
      "grad_norm": 0.26968345046043396,
      "learning_rate": 4.047619047619048e-06,
      "loss": 3.9314,
      "step": 670
    },
    {
      "epoch": 4.0,
      "eval_loss": 3.889238119125366,
      "eval_runtime": 7.977,
      "eval_samples_per_second": 673.809,
      "eval_steps_per_second": 5.265,
      "step": 672
    },
    {
      "epoch": 4.0476190476190474,
      "grad_norm": 0.2838389277458191,
      "learning_rate": 3.80952380952381e-06,
      "loss": 3.9338,
      "step": 680
    },
    {
      "epoch": 4.107142857142857,
      "grad_norm": 0.25133568048477173,
      "learning_rate": 3.5714285714285718e-06,
      "loss": 3.9291,
      "step": 690
    },
    {
      "epoch": 4.166666666666667,
      "grad_norm": 0.2738380432128906,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 3.9304,
      "step": 700
    },
    {
      "epoch": 4.226190476190476,
      "grad_norm": 0.24620091915130615,
      "learning_rate": 3.0952380952380957e-06,
      "loss": 3.9308,
      "step": 710
    },
    {
      "epoch": 4.285714285714286,
      "grad_norm": 0.2830589711666107,
      "learning_rate": 2.8571428571428573e-06,
      "loss": 3.9315,
      "step": 720
    },
    {
      "epoch": 4.345238095238095,
      "grad_norm": 0.294011652469635,
      "learning_rate": 2.6190476190476192e-06,
      "loss": 3.9286,
      "step": 730
    },
    {
      "epoch": 4.404761904761905,
      "grad_norm": 0.2506384253501892,
      "learning_rate": 2.380952380952381e-06,
      "loss": 3.93,
      "step": 740
    },
    {
      "epoch": 4.464285714285714,
      "grad_norm": 0.235085129737854,
      "learning_rate": 2.1428571428571427e-06,
      "loss": 3.9288,
      "step": 750
    },
    {
      "epoch": 4.523809523809524,
      "grad_norm": 0.2391151785850525,
      "learning_rate": 1.904761904761905e-06,
      "loss": 3.9299,
      "step": 760
    },
    {
      "epoch": 4.583333333333333,
      "grad_norm": 0.23899592459201813,
      "learning_rate": 1.6666666666666667e-06,
      "loss": 3.9283,
      "step": 770
    },
    {
      "epoch": 4.642857142857143,
      "grad_norm": 0.29169049859046936,
      "learning_rate": 1.4285714285714286e-06,
      "loss": 3.9294,
      "step": 780
    },
    {
      "epoch": 4.7023809523809526,
      "grad_norm": 0.27030590176582336,
      "learning_rate": 1.1904761904761906e-06,
      "loss": 3.927,
      "step": 790
    },
    {
      "epoch": 4.761904761904762,
      "grad_norm": 0.2551476061344147,
      "learning_rate": 9.523809523809525e-07,
      "loss": 3.93,
      "step": 800
    },
    {
      "epoch": 4.821428571428571,
      "grad_norm": 0.23873929679393768,
      "learning_rate": 7.142857142857143e-07,
      "loss": 3.9313,
      "step": 810
    },
    {
      "epoch": 4.880952380952381,
      "grad_norm": 0.23298774659633636,
      "learning_rate": 4.7619047619047623e-07,
      "loss": 3.9319,
      "step": 820
    },
    {
      "epoch": 4.940476190476191,
      "grad_norm": 0.2884943187236786,
      "learning_rate": 2.3809523809523811e-07,
      "loss": 3.9292,
      "step": 830
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.2528243958950043,
      "learning_rate": 0.0,
      "loss": 3.9302,
      "step": 840
    },
    {
      "epoch": 5.0,
      "eval_loss": 3.886491298675537,
      "eval_runtime": 8.0501,
      "eval_samples_per_second": 667.691,
      "eval_steps_per_second": 5.217,
      "step": 840
    }
  ],
  "logging_steps": 10,
  "max_steps": 840,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 128,
  "trial_name": null,
  "trial_params": null
}
