{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling Using Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and preprocess the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 20 Newsgroups dataset\n",
    "newsgroups = fetch_20newsgroups(\n",
    "    subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'text': newsgroups.data, 'target': newsgroups.target})\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Train set size: {len(train_df)}\")\n",
    "print(f\"Test set size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a custom dataset and data module for fine-tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsGroupsDataset(Dataset):\n",
    "    def __init__(self, texts, targets):\n",
    "        self.texts = texts\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], self.targets[idx]\n",
    "\n",
    "\n",
    "class NewsGroupsDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_df, test_df, batch_size=32):\n",
    "        super().__init__()\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = NewsGroupsDataset(\n",
    "            self.train_df['text'].tolist(), self.train_df['target'].tolist())\n",
    "        self.test_dataset = NewsGroupsDataset(\n",
    "            self.test_df['text'].tolist(), self.test_df['target'].tolist())\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune the SentenceTransformer model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "class SentenceTransformerFinetuner(pl.LightningModule):\n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2', lr=2e-5):\n",
    "        super().__init__()\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.lr = lr\n",
    "\n",
    "    def forward(self, batch):\n",
    "        return self.model.encode(batch, convert_to_tensor=True)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        texts, labels = batch\n",
    "        embeddings = self(texts)\n",
    "\n",
    "        # Ensure embeddings require gradients\n",
    "        if not embeddings.requires_grad:\n",
    "            embeddings.requires_grad_(True)\n",
    "\n",
    "        # Calculate pairwise distances\n",
    "        distances = torch.cdist(embeddings, embeddings)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = self.model.get_sentence_embedding_dimension() - distances.mean()\n",
    "\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Ensure all parameters require gradients\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        optimizer = AdamW(self.model.parameters(), lr=self.lr)\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=0,\n",
    "            num_training_steps=self.trainer.estimated_stepping_batches\n",
    "        )\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "\n",
    "# Initialize the data module and model\n",
    "data_module = NewsGroupsDataModule(train_df, test_df)\n",
    "model = SentenceTransformerFinetuner()\n",
    "\n",
    "# Train the model\n",
    "trainer = pl.Trainer(max_epochs=3, accelerator='auto')\n",
    "trainer.fit(model, data_module)\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.model.save('fine_tuned_sentence_transformer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train the BERTopic model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fine-tuned SentenceTransformer model\n",
    "sentence_model = SentenceTransformer('fine_tuned_sentence_transformer')\n",
    "\n",
    "# Initialize UMAP and HDBSCAN\n",
    "umap_model = UMAP(n_neighbors=15, n_components=5,\n",
    "                  min_dist=0.0, metric='cosine')\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=15, metric='euclidean',\n",
    "                        cluster_selection_method='eom', prediction_data=True)\n",
    "\n",
    "# Initialize CountVectorizer\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "# Create and train BERTopic model\n",
    "topic_model = BERTopic(\n",
    "    embedding_model=sentence_model,\n",
    "    umap_model=umap_model,\n",
    "    hdbscan_model=hdbscan_model,\n",
    "    vectorizer_model=vectorizer_model,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "topics, _ = topic_model.fit_transform(train_df['text'].tolist())\n",
    "\n",
    "print(\"BERTopic model training completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_topic_model(topic_model, test_df):\n",
    "    # Get predictions on test data\n",
    "    test_topics, _ = topic_model.transform(test_df['text'].tolist())\n",
    "\n",
    "    # Calculate coherence score\n",
    "    coherence_score = topic_model.get_topic_info()['Coherence'].mean()\n",
    "\n",
    "    # Calculate diversity score (unique words in top N words per topic)\n",
    "    N = 20\n",
    "    topic_words = [word for topic in topic_model.get_topics().values()\n",
    "                   for word, _ in topic[:N]]\n",
    "    diversity_score = len(set(topic_words)) / \\\n",
    "        (len(topic_model.get_topics()) * N)\n",
    "\n",
    "    # Calculate topic quality using Adjusted Rand Index and Normalized Mutual Information\n",
    "    true_labels = test_df['target'].tolist()\n",
    "    ari = adjusted_rand_score(true_labels, test_topics)\n",
    "    nmi = normalized_mutual_info_score(true_labels, test_topics)\n",
    "\n",
    "    return {\n",
    "        'coherence_score': coherence_score,\n",
    "        'diversity_score': diversity_score,\n",
    "        'adjusted_rand_index': ari,\n",
    "        'normalized_mutual_info': nmi\n",
    "    }\n",
    "\n",
    "\n",
    "evaluation_results = evaluate_topic_model(topic_model, test_df)\n",
    "print(\"Evaluation Results:\")\n",
    "for metric, value in evaluation_results.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize topics\n",
    "topic_model.visualize_topics().write_html(\"topic_visualization.html\")\n",
    "print(\"Topic visualization saved as 'topic_visualization.html'\")\n",
    "\n",
    "# Visualize topic distribution\n",
    "topic_distr = topic_model.get_topic_info()\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Topic', y='Count', data=topic_distr)\n",
    "plt.title('Topic Distribution')\n",
    "plt.xlabel('Topic')\n",
    "plt.ylabel('Number of Documents')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.savefig('topic_distribution.png')\n",
    "plt.close()\n",
    "print(\"Topic distribution plot saved as 'topic_distribution.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function to get topics for new text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topics_for_text(texts, topic_model):\n",
    "    topics, probs = topic_model.transform(texts)\n",
    "    return list(zip(topics, probs))\n",
    "\n",
    "\n",
    "# Example usage\n",
    "new_texts = [\n",
    "    \"This is a sample text about computer science and programming.\",\n",
    "    \"The stock market experienced significant fluctuations today.\"\n",
    "]\n",
    "new_topics = get_topics_for_text(new_texts, topic_model)\n",
    "for text, (topic, prob) in zip(new_texts, new_topics):\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Assigned Topic: {topic}\")\n",
    "    print(f\"Probability: {prob}\")\n",
    "    print(\n",
    "        f\"Top words: {', '.join([word for word, _ in topic_model.get_topic(topic)])}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write tests for the topic modeling pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "\n",
    "class TestTopicModeling(unittest.TestCase):\n",
    "    @classmethod\n",
    "    def setUpClass(cls):\n",
    "        # Load the trained model and necessary data\n",
    "        cls.topic_model = BERTopic.load(\"trained_bertopic_model\")\n",
    "        cls.test_df = pd.read_csv(\"test_data.csv\")\n",
    "\n",
    "    def test_model_output_format(self):\n",
    "        topics, probs = self.topic_model.transform(\n",
    "            self.test_df['text'].tolist())\n",
    "        self.assertEqual(len(topics), len(self.test_df))\n",
    "        self.assertEqual(len(probs), len(self.test_df))\n",
    "        self.assertTrue(all(isinstance(topic, int) for topic in topics))\n",
    "        self.assertTrue(all(isinstance(prob, float) and 0 <=\n",
    "                        prob <= 1 for prob in probs))\n",
    "\n",
    "    def test_topic_coherence(self):\n",
    "        coherence_score = self.topic_model.get_topic_info()['Coherence'].mean()\n",
    "        self.assertGreater(coherence_score, 0.3)  # Adjust threshold as needed\n",
    "\n",
    "    def test_topic_diversity(self):\n",
    "        N = 20\n",
    "        topic_words = [word for topic in self.topic_model.get_topics().values()\n",
    "                       for word, _ in topic[:N]]\n",
    "        diversity_score = len(set(topic_words)) / \\\n",
    "            (len(self.topic_model.get_topics()) * N)\n",
    "        self.assertGreater(diversity_score, 0.5)  # Adjust threshold as needed\n",
    "\n",
    "    def test_new_text_assignment(self):\n",
    "        new_text = \"This is a sample text about artificial intelligence and machine learning.\"\n",
    "        topic, prob = self.topic_model.transform([new_text])[0]\n",
    "        self.assertIsInstance(topic, int)\n",
    "        self.assertIsInstance(prob, float)\n",
    "        self.assertTrue(0 <= prob <= 1)\n",
    "\n",
    "    def test_model_consistency(self):\n",
    "        text = \"This is a test text for consistency.\"\n",
    "        topics1, _ = self.topic_model.transform([text])\n",
    "        topics2, _ = self.topic_model.transform([text])\n",
    "        self.assertEqual(topics1, topics2)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and load the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "topic_model.save(\"trained_bertopic_model\")\n",
    "print(\"Model saved as 'trained_bertopic_model'\")\n",
    "\n",
    "# Load the model (for future use)\n",
    "loaded_model = BERTopic.load(\"trained_bertopic_model\")\n",
    "print(\"Model loaded successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
